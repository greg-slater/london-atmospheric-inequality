chocData <- read_csv("/home/greg/Downloads/flavors_of_cacao.csv")
names(chocData)
# function to neaten up column names from input table
niceCols <- function(df){
# make unique
names(df) <- make.names(names(df), unique=TRUE)
# make lowercase
names(df) <- tolower(names(df))
# replace 'full stops '.' with '_'
names(df) <- gsub(x = names(df),
pattern = "(\\.)+",
replacement = "_")
df
}
# run column function
chocData <- niceCols(chocData)
# remove first row
chocData <- chocData[-1,]
# convert columns into correct types
chocData <- type_convert(chocData)
# remove % symbol from cocoa_percent column which is still a character
chocData$cocoa_percent <- sapply(chocData$cocoa_percent, function(x) gsub("%", "", x))
chocData <- type_convert(chocData)
head(chocData)
str(chocData)
# group by bean type, mean rating, then order
chocData %>%
group_by(broad_bean_origin) %>%
summarise(mean_rating = mean(rating)) %>%
arrange(desc(mean_rating))
library(tidyverse)
library(tidyverse)
chocData <- read_csv("/home/greg/Downloads/flavors_of_cacao.csv")
names(chocData)
# function to neaten up column names from input table
niceCols <- function(df){
# make unique
names(df) <- make.names(names(df), unique=TRUE)
# make lowercase
names(df) <- tolower(names(df))
# replace 'full stops '.' with '_'
names(df) <- gsub(x = names(df),
pattern = "(\\.)+",
replacement = "_")
df
}
# run column function
chocData <- niceCols(chocData)
# remove first row
chocData <- chocData[-1,]
# convert columns into correct types
chocData <- type_convert(chocData)
# remove % symbol from cocoa_percent column which is still a character
chocData$cocoa_percent <- sapply(chocData$cocoa_percent, function(x) gsub("%", "", x))
chocData <- type_convert(chocData)
head(chocData)
str(chocData)
# group by bean type, mean rating, then order
chocData %>%
group_by(broad_bean_origin) %>%
summarise(mean_rating = mean(rating)) %>%
arrange(desc(mean_rating))
library(tidyverse)
library(randomForest)
library(rpart)
df <- read_csv("/home/greg/Downloads/melb_data.csv")
df <- read_csv("/home/greg/Documents/melb_data.csv")
describe(df)
summarise(df)
df
summarize(df)
summary(df)
names(df)
fit <- rpart(Price ~ Rooms + Bathroom + Landsize + BuldingArea + YearBuilt
+ Lattitude + Longtitude, data=df)
fit <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt
+ Lattitude + Longtitude, data=df)
plot(fit, uniform=True)
plot(fit, uniform=TRUE)
text(fit, cex=.6)
plot(fit, uniform=TRUE)
text(fit, cex=.6)
print(predict(fit, head(df)))
print(head(df$Price))
library(modelr)
mae(model = fit, data = df)
splitData <- resample_partition(df, c(test=0.3, train=0.7))
lapply(splitData, dim)
splitData
splitData$test
summary(splitData$test)
str(splitData$test)
# create second model using the training data
fit2 <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt
+ Lattitude + Longtitude, data=splitData$train)
mae(model = fit2, data = splitData$test)
# create second model using the training data
fit2 <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt
#+ Lattitude + Longtitude
, data=splitData$train)
mae(model = fit2, data = splitData$test)
# create second model using the training data
fit2 <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea + YearBuilt
+ Lattitude + Longtitude, data=splitData$train)
mae(model = fit2, data = splitData$test)
target <- "Price"
predictors <-  c("Rooms","Bathroom","Landsize","BuildingArea",
"YearBuilt","Lattitude","Longtitude")
p<- paste(predictors, collapse="+")
formula <- as.formula(paste(target,"~",p,sep = ""))
p
p<- paste(predictors, collapse=" + ")
p
formula <- as.formula(paste(target,"~",p,sep = ""))
formula
formula <- as.formula(paste(target,"~", p, sep = " "))
formula
formula <- as.formula(paste(target,"~", p))
formula
p<- paste(predictors, sep="+")
p
collapse
p
predictors <-  c("Rooms","Bathroom","Landsize","BuildingArea",
"YearBuilt","Lattitude","Longtitude")
p<- paste(predictors, collapse=" + ")
p
p<- paste(predictors, sep=" + ")
p
p<- paste(predictors, collapse=" + ")
p
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app_backup_20181229_1800")
library(shiny)
library(leaflet)
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(RColorBrewer)
runApp()
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
levels(sf$LAD17NM)
sf <- st_read('london_lsoa_NO2_gen/london_lsoa_NO2_gen.shp')
levels(sf$LAD17NM)
sf
library(shiny)
library(leaflet)
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(RColorBrewer)
rsconnect::deployApp()
runApp()
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app_FINAL")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(shiny)
library(leaflet)
library(dplyr)
library(tidyr)
library(ggplot2)
library(sf)
library(RColorBrewer)
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app")
runApp()
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app_FINAL")
runApp()
runApp()
runApp()
setwd("/media/greg/Windows/Users/Greg/Documents/MASTERS/MOD - GIS/Assessment/assessment_3/shiny_app_FINAL")
runApp()
rsconnect::deployApp()
runApp()
runApp()
install.packages('tinytex')
tinytex::install_tinytex()
